About the certification:

The objective of this certification is to assess your skills in a practical Analytics Engineering project following the Modern Analytics Stack methodology, developed by Indicium but which shares many similarities with the Modern Data Stack used by thousands of modern data teams.

Obtaining this certification indicates that you:
Understand the process of building a modern analytics platform; Understand the objectives of dimensional modeling in modern data warehouses; Know how to apply SQL and the dbt tool to model data in modern data warehouses; Understand best practices for data visualization and their application in a self-service BI tool.


Project Context:

The following company has hired you: Adventure Works (AW), a rapidly growing bicycle manufacturer boasting over 500 distinct products, 20,000 customers, and 31,000 orders. To maintain its growth and differentiate itself from the competition, Adventure Works wants to use its data strategically, guiding its decisions to become a data-driven company. Adventure Works' management has already listed a series of questions it wants to answer through data cross-referencing, which should guide the development of the data warehouse's fact and dimension tables. To kick off the project and achieve rapid results, the decision was made to begin with the sales department, but some tables from other departments may be necessary to obtain the desired information. In your initial assessment, you identified some systems Adventure Works uses that generate data relevant to the business and that, at some point, should be part of the data infrastructure:

Function [System]
ERP [SAP]
CRM [SalesForce]
Web Analytics [Google Analytics]
Website [Wordpress]

 
In your initial conversations, you also identified that the project isn't unanimous within the company, and that there are questions about the timeline, costs involved, and whether there will be a return on investment. The project was conceived and sponsored by AW's innovation director, João Muller, and also has the support of the company's CEO, Carlos Silveira, who sees the use of data as a strategic differentiator in the long term. However, in the view of commercial director Silvana Teixeira, the amount invested in the project could have been directed towards promotional activities that, in her opinion, generate immediate sales results. Furthermore, she still doesn't see how creating a modern data infrastructure will help her sales department, as promises to make the area data-driven, made by other system vendors (such as CRM and Web Analytics), have failed to deliver the promised results. A special request from CEO Carlos Silveira is that the construction of this data platform ensure the quality and veracity of the output data—that is, that the Analytics Engineering team can confirm that the information is consistent with what was gathered by the accounting audit team. One example Carlos mentioned was that gross sales in 2011 were $12,646,112.16. Therefore, he would like tests to be performed to ensure the veracity of this value in the models that will be built, based on a Modern Data Stack workshop he recently attended. In addition to these individuals, IT Director Nilson Ramos is responsible for ensuring data access and has appointed an analyst, Gabriel Santos, to assist him with this. Gabriel is currently responsible for managing the databases and answering specific questions from business areas that require SQL. He has a very limited schedule, so coordinating communication and agile interactions are essential to ensure all necessary data is available for the project.

Data Description Adventure Works has a transactional database (PostgreSQL) that stores data from its various departments. This data is distributed across 68 tables divided into five schemas: HR, sales, production, and purchasing. To access this complete diagram, use this link.
Data Ingestion Instructions (DI) The database used in the course contains a schema called raw_adventure_works that should be used as the raw data.


Deliverable: Adventure Works relies on your technical capabilities to design and implement your modern analytics infrastructure from start to finish, which should include items 1 through 5 below.

1 - Conceptual data warehouse diagram in PDF format: Create the conceptual model with the fact and dimension tables needed to answer the business questions in item 4. Briefly demonstrate which source tables were used to create each dimension and the fact table. (Tool suggestion: draw.io)

2 - Setting up a cloud data warehouse and dbt configuration. Suggestion: Snowflake and dbt Cloud. 

3 - Data transformation: Transform the raw data using dbt (suggestion: dbt Cloud). This transformation should include the following: a - Documenting the tables and columns in the marts b - Testing sources c - Testing the primary keys of the dimension and fact tables d - Data testing (remember Carlos's request) e - The code must be in a repository (suggestion: GitHub). You must provide the repository link on GitHub.

4 - BI Dashboards: Create them in a tool of your choice, but one that allows you to answer the following business questions: a - What is the number of orders, quantity purchased, total value transacted per product, card type, reason for sale, date of sale, customer, status, city, state, and country? b - Which products have the highest average ticket per month, year, city, state, and country? (Average ticket = Gross revenue - product discounts / number of orders in the analysis period) c - Who are the top 10 customers by total value transacted filtered by product, card type, reason for sale, date of sale, status, city, state, and country? d - Which are the top 5 cities in total value transacted by product, card type, reason for sale, date of sale, customer, status, city, state, and country? e - What is the number of orders, quantity purchased, and total value transacted by month and year (hint: time series chart)? f - Which product has the highest number of units purchased for the "Promotion" reason for sale? These are the minimum questions that must be answered by analyses performed on the created dashboard, but a complete and well-structured dashboard will also count towards the final evaluation of the BI item delivery.
Suggested tools: Google Data Studio - you must provide the dashboard link for us to access; PowerBI - provide the dashboard file; In short, if you use another tool, remember that the dashboard must be interactive and that we must have access to the dashboard. Screenshots of the dashboards will not be considered in the evaluation.
5 - Video: You must record a video presenting all the project steps (DW, EL, transformation to dbt, and BI). Create it with a recording tool, such as Nimbus or OBS Studio. The video should be no longer than 10 minutes. You can use YouTube or another portal if you wish.

Below is a basic storytelling guide for your video. You can include more information, such as modeling decisions, metrics created, and different analyses that can be derived from your dashboard in addition to those mentioned in item 4. However, it is imperative that your video include the following demonstrations: A brief explanation of the project objective and expected results. An explanation of the dimensions that were created and their relationship to the fact table. A demonstration of the dbt run where we can see that all models run successfully. Use dbt run. A demonstration that all tests applied to the source pass. Use dbt test –select source:*. A demonstration that all tests applied to the models pass. Use dbt test. A demonstration of the fact table and joins made between the fact table and the dimensions. Which metrics were created in the fact table and why. Present the data test. Presentation of the dashboard, how filters work, visualizations, possible analyses, and also present the answer to item 4-f.

[OPTIONAL]: Data Project Plan in PDF format: Consider the information you gathered in the initial assessments and summarized in the context. In particular, consider the expected objectives, stakeholders, and project risks/contingencies. Additionally, what other values can we derive from data infrastructure projects? Are there any other risks and contingencies you think are relevant to include in the project plan (use the template in the attachment in the upper right corner of the page).

Delivery Method: All project steps must be archived in a WinRAR file or Zip folder and submitted through the platform as follows: 1 - GitHub: You must submit the entire project to GitHub via a link in a text file in the folder. 2 - YouTube/Drive/Dropbox: You must embed the video on one of these platforms via a link in a text file in the folder. 3 - Conceptual Model: You must insert the Final Project Conceptual Model in the WinRAR or Zip folder. Note: If this folder exceeds Moodle's 40 MB limit, you can put the entire project in a WinRAR or Zip file and place it in a folder on Google Drive and send us the link via a text file. Remember to share the file with permission to speed up the review process. Suggested file name: CEA_AW_YOURNAME

Evaluation: Our evaluation has a total of 10 points and considers criteria such as: Compliance with delivery requirements; Professionalism in delivery and presentation; and clarity/understanding of content. The minimum passing score is 7. You have 30 days after registering to submit the challenge. If you don't meet the criteria, you'll have a second chance to correct any deficiencies. The second chance is 10 days after submitting feedback.

Data Dictionary To facilitate data comprehension, Adventure Works has provided a data dictionary for your project, including some definitions they use internally. Since the client currently uses reports exported by the system, other tables may be required to obtain the information, and it's up to you to identify these relationships. Dimension Column in DB Tables Customer person.Name Customer/Person Reason for sale salesreason.Name Sales Reason Salesperson person.Name Salesperson/Employee/Person State Stateprovince.Name State Province City Address.City Address Country Countryregion.Name Country Region Date of sale Salesorderheader.orderdate Sales Order Header Product Product.name Sales Order Detail/ Product Metric Calculation Primary table Number of orders distinct count of salesorderid Sales Order Header Quantity purchased sum of orderqty Sales Order Detail Total negotiated amount sum of [unitprice*orderqty] Sales Order Detail Total negotiated amount net sum of [unitprice * orderqty - (1-discount)] Sales Order Detail Instructions You have 30 days after registering to submit the challenge. After clicking the "Submit" button, you will only have one chance to submit the required materials. Therefore, only do so when you have completed your activities.
